{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP | V NP PP\n",
    "PP -> P NP\n",
    "V -> \"saw\" | \"ate\" | \"walked\"\n",
    "NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = \"Mary saw Bob\".split()\n",
    "# rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "# for tree in rd_parser.parse(sent):\n",
    "#     print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar2 = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det Nom | PropN\n",
    "    Nom -> Adj Nom | N\n",
    "    VP -> V Adj | V NP | V S | V NP PP\n",
    "    PP -> P NP\n",
    "    PropN -> 'Buster' | 'Chatterer' | 'Joe'\n",
    "    Det -> 'the' | 'a'\n",
    "    N -> 'bear' | 'squirrel' | 'tree' | 'fish' | 'log'\n",
    "    Adj -> 'angry' | 'frightened' | 'little' | 'tall'\n",
    "    V -> 'chased' | 'saw' | 'said' | 'thought' | 'was' | 'put'\n",
    "    P -> 'on'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "sent = 'Mary saw a dog'.split()\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'Mary saw a dog'\n",
      "    [ * Mary saw a dog]\n",
      "  S [ 'Mary' * saw a dog]\n",
      "  R [ NP * saw a dog]\n",
      "  S [ NP 'saw' * a dog]\n",
      "  R [ NP V * a dog]\n",
      "  S [ NP V 'a' * dog]\n",
      "  R [ NP V Det * dog]\n",
      "  S [ NP V Det 'dog' * ]\n",
      "  R [ NP V Det N * ]\n",
      "  R [ NP V NP * ]\n",
      "  R [ NP VP * ]\n",
      "  R [ S * ]\n",
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "sr_parser = nltk.ShiftReduceParser(grammar1, trace=2)\n",
    "sent = 'Mary saw a dog'.split()\n",
    "for tree in sr_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[V -> 'shot']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "groucho_grammar.productions(rhs=text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(NP, VP): S,\n",
       " (P, NP): PP,\n",
       " (Det, N): NP,\n",
       " (Det, N, PP): NP,\n",
       " ('I',): NP,\n",
       " (V, NP): VP,\n",
       " (VP, PP): VP,\n",
       " ('an',): Det,\n",
       " ('my',): Det,\n",
       " ('elephant',): N,\n",
       " ('pajamas',): N,\n",
       " ('shot',): V,\n",
       " ('in',): P}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = dict((p.rhs(), p.lhs()) for p in groucho_grammar.productions())\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for w in range(2, 5):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_wfst(tokens, grammar):\n",
    "    numtokens = len(tokens)\n",
    "    wfst = [[None for i in range(numtokens+1)] for j in range(numtokens+1)]\n",
    "    for i in range(numtokens):\n",
    "        productions = grammar.productions(rhs=tokens[i])\n",
    "        wfst[i][i+1] = productions[0].lhs\n",
    "    return wfst\n",
    "\n",
    "def complete_wfst(wfst, tokens, grammar, trace=False):\n",
    "    index = dict((p.rhs(), p.lhs()) for p in grammar.productions())\n",
    "    numtokens = len(tokens)\n",
    "    for span in range(2, numtokens+1):\n",
    "        for start in range(numtokens+1-span):\n",
    "            end = start + span\n",
    "            for mid in range(start+1, end):\n",
    "                nt1, nt2 = wfst[start][mid], wfst[mid][end]\n",
    "                if nt1 and nt2 and (nt1, nt2) in index:\n",
    "                    wfst[start][end] = index[(nt1, nt2)]\n",
    "                    if trace:\n",
    "                        print(\"[%s] %3s [%s] %3s [%s] ==> [%s] %3s [%s]\" % \\\n",
    "                             (start, nt1, mid, nt2, end, start, index[(nt1, nt2)], end))\n",
    "    return wfst\n",
    "\n",
    "def display(wfst, tokens):\n",
    "    print('\\nWFST ' + ' '.join((\"%-4d\" % i) for i in range(1, len(wfst))))\n",
    "    for i in range(len(wfst)-1):\n",
    "        print(\"%d    \" % i, end=\" \")\n",
    "        for j in range(1, len(wfst)):\n",
    "            print(\"%-4s\" % (wfst[i][j] or '.'), end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WFST 1    2    3    4    5    6    7   \n",
      "0     <bound method Production.lhs of NP -> 'I'> .    .    .    .    .    .    \n",
      "1     .    <bound method Production.lhs of V -> 'shot'> .    .    .    .    .    \n",
      "2     .    .    <bound method Production.lhs of Det -> 'an'> .    .    .    .    \n",
      "3     .    .    .    <bound method Production.lhs of N -> 'elephant'> .    .    .    \n",
      "4     .    .    .    .    <bound method Production.lhs of P -> 'in'> .    .    \n",
      "5     .    .    .    .    .    <bound method Production.lhs of Det -> 'my'> .    \n",
      "6     .    .    .    .    .    .    <bound method Production.lhs of N -> 'pajamas'> \n"
     ]
    }
   ],
   "source": [
    "tokens = \"I shot an elephant in my pajamas\".split()\n",
    "wfst0 = init_wfst(tokens, groucho_grammar)\n",
    "display(wfst0, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfst1 = complete_wfst(wfst0, tokens, groucho_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WFST 1    2    3    4    5    6    7   \n",
      "0     <bound method Production.lhs of NP -> 'I'> .    .    .    .    .    .    \n",
      "1     .    <bound method Production.lhs of V -> 'shot'> .    .    .    .    .    \n",
      "2     .    .    <bound method Production.lhs of Det -> 'an'> .    .    .    .    \n",
      "3     .    .    .    <bound method Production.lhs of N -> 'elephant'> .    .    .    \n",
      "4     .    .    .    .    <bound method Production.lhs of P -> 'in'> .    .    \n",
      "5     .    .    .    .    .    <bound method Production.lhs of Det -> 'my'> .    \n",
      "6     .    .    .    .    .    .    <bound method Production.lhs of N -> 'pajamas'> \n"
     ]
    }
   ],
   "source": [
    "display(wfst1, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfst1 = complete_wfst(wfst0, tokens, groucho_grammar, trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grammar= (\n",
      "('    ', 'S -> NP VP,')\n",
      "('    ', 'VP -> VP PP,')\n",
      "('    ', 'VP -> V NP,')\n",
      "('    ', 'VP -> V,')\n",
      "('    ', 'NP -> Det N,')\n",
      "('    ', 'NP -> NP PP,')\n",
      "('    ', 'PP -> P NP,')\n",
      "('    ', \"NP -> 'John',\")\n",
      "('    ', \"NP -> 'I',\")\n",
      "('    ', \"Det -> 'the',\")\n",
      "('    ', \"Det -> 'my',\")\n",
      "('    ', \"Det -> 'a',\")\n",
      "('    ', \"N -> 'dog',\")\n",
      "('    ', \"N -> 'cookie',\")\n",
      "('    ', \"N -> 'table',\")\n",
      "('    ', \"N -> 'cake',\")\n",
      "('    ', \"N -> 'fork',\")\n",
      "('    ', \"V -> 'ate',\")\n",
      "('    ', \"V -> 'saw',\")\n",
      "('    ', \"P -> 'on',\")\n",
      "('    ', \"P -> 'under',\")\n",
      "('    ', \"P -> 'with',\")\n",
      ")\n",
      "tokens = ['John', 'ate', 'the', 'cake', 'on', 'the', 'table']\n",
      "Calling \"ChartParserApp(grammar, tokens)\"...\n"
     ]
    }
   ],
   "source": [
    "nltk.app.chartparser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency grammar with 7 productions\n",
      "  'shot' -> 'I'\n",
      "  'shot' -> 'elephant'\n",
      "  'shot' -> 'in'\n",
      "  'elephant' -> 'an'\n",
      "  'elephant' -> 'in'\n",
      "  'in' -> 'pajamas'\n",
      "  'pajamas' -> 'my'\n"
     ]
    }
   ],
   "source": [
    "groucho_dep_grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
    "    'shot' -> 'I' | 'elephant' | 'in'\n",
    "    'elephant' -> 'an' | 'in'\n",
    "    'in' -> 'pajamas'\n",
    "    'pajamas' -> 'my'\n",
    "\"\"\")\n",
    "print(groucho_dep_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(shot I (elephant an (in (pajamas my))))\n",
      "(shot I (elephant an) (in (pajamas my)))\n"
     ]
    }
   ],
   "source": [
    "pdp = nltk.ProjectiveDependencyParser(groucho_dep_grammar)\n",
    "sent = 'I shot an elephant in my pajamas'.split()\n",
    "trees = pdp.parse(sent)\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
